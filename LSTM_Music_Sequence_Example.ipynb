{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMlR4aa1xeQJOc4gTZIBi3i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaellomuscio/LSTM_Sound_Example/blob/main/LSTM_Music_Sequence_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Music Sequence Prediction using LSTMs\n",
        "\n",
        "*Written by Dr. Michael Lomuscio*\n",
        "\n",
        "This Google Colab notebook demonstrates a basic implementation of a music sequence prediction model using Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN). The primary focus of this project is to predict the next musical note in a sequence based on the preceding notes, simulating how music might be composed or predicted based on prior patterns. Below, we'll provide a brief introduction to LSTMs and how they are utilized in this project.\n",
        "\n",
        "## Key Concepts and Models Used\n",
        "\n",
        "### 1. LSTM Networks\n",
        "LSTMs are a type of Recurrent Neural Network designed to recognize patterns in sequences of data. They are particularly useful for time-series data like music, where past notes have an influence on future notes. In this code, LSTMs are employed to learn the relationships between notes and predict the next note in a sequence. LSTMs are ideal for this task because they have memory cells that can maintain information over longer time intervals, making them well-suited for dealing with sequential data where the order of elements matters.\n",
        "\n",
        "### 2. Music Note Mapping and Sequence Creation\n",
        "The model first converts a set of musical notes (C, D, E, F, G, A, B) into numeric representations, which are more suitable for machine learning algorithms. This numerical encoding allows the model to process the notes as numerical data, which is essential for training the LSTM. In this notebook, a sequence of musical notes is defined, and input-output pairs are generated to train the model.\n",
        "\n",
        "### 3. Model Structure\n",
        "The model uses a Sequential API from TensorFlow's Keras library to create a simple LSTM-based neural network. It has two main layers:\n",
        "- **LSTM Layer:** This layer processes the sequence of notes and captures the temporal dependencies among them.\n",
        "- **Dense Layer:** The Dense layer with a softmax activation outputs a probability distribution over the possible notes, allowing the model to predict the next note.\n",
        "\n",
        "### 4. Training Process\n",
        "The model is trained to predict the next note in a sequence based on a sliding window of previous notes. The training data is constructed by slicing the original sequence into smaller overlapping subsequences. For example, given the sequence [C, D, E, F, G, A, B, C, D, E], the model learns using smaller chunks like [C, D, E] to predict F, [D, E, F] to predict G, and so on.\n",
        "\n",
        "## How to Use This Code\n",
        "\n",
        "1. **Dependencies**  \n",
        "   Make sure you have TensorFlow and NumPy installed. You can install them in Google Colab using the following commands:\n",
        "   ```python\n",
        "   !pip install tensorflow\n",
        "   !pip install numpy\n"
      ],
      "metadata": {
        "id": "1-RWwRE_r2Qz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqyRdZ64qvvU",
        "outputId": "0f3679fa-fc2d-4ad5-abdb-09daf5830496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted sequence to integers: [0, 1, 2, 3, 4, 5, 6, 0, 1, 2]\n",
            "Sequence 6: Input: [6, 0, 1], Output: 2\n",
            "X shape: (7, 3), y shape: (7,)\n",
            "Reshaped X: (7, 3, 1)\n",
            "Normalized X: [[[0.        ]\n",
            "  [0.14285714]\n",
            "  [0.28571429]]\n",
            "\n",
            " [[0.14285714]\n",
            "  [0.28571429]\n",
            "  [0.42857143]]\n",
            "\n",
            " [[0.28571429]\n",
            "  [0.42857143]\n",
            "  [0.57142857]]\n",
            "\n",
            " [[0.42857143]\n",
            "  [0.57142857]\n",
            "  [0.71428571]]\n",
            "\n",
            " [[0.57142857]\n",
            "  [0.71428571]\n",
            "  [0.85714286]]\n",
            "\n",
            " [[0.71428571]\n",
            "  [0.85714286]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.85714286]\n",
            "  [0.        ]\n",
            "  [0.14285714]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added LSTM layer with 50 units.\n",
            "Added Dense layer with softmax activation.\n",
            "Compiled the model with sparse categorical crossentropy and adam optimizer.\n",
            "Starting model training...\n",
            "Epoch 1/200\n",
            "7/7 - 2s - 292ms/step - loss: 1.9631\n",
            "Epoch 2/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9565\n",
            "Epoch 3/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9541\n",
            "Epoch 4/200\n",
            "7/7 - 0s - 5ms/step - loss: 1.9509\n",
            "Epoch 5/200\n",
            "7/7 - 0s - 5ms/step - loss: 1.9492\n",
            "Epoch 6/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9466\n",
            "Epoch 7/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9445\n",
            "Epoch 8/200\n",
            "7/7 - 0s - 5ms/step - loss: 1.9429\n",
            "Epoch 9/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9414\n",
            "Epoch 10/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9396\n",
            "Epoch 11/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9370\n",
            "Epoch 12/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9354\n",
            "Epoch 13/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9330\n",
            "Epoch 14/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9308\n",
            "Epoch 15/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9284\n",
            "Epoch 16/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9258\n",
            "Epoch 17/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9231\n",
            "Epoch 18/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9208\n",
            "Epoch 19/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9184\n",
            "Epoch 20/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9143\n",
            "Epoch 21/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9132\n",
            "Epoch 22/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9082\n",
            "Epoch 23/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9047\n",
            "Epoch 24/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.9000\n",
            "Epoch 25/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8980\n",
            "Epoch 26/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8897\n",
            "Epoch 27/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8857\n",
            "Epoch 28/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8790\n",
            "Epoch 29/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8731\n",
            "Epoch 30/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8652\n",
            "Epoch 31/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8568\n",
            "Epoch 32/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8484\n",
            "Epoch 33/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8414\n",
            "Epoch 34/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8283\n",
            "Epoch 35/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8207\n",
            "Epoch 36/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.8042\n",
            "Epoch 37/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.7909\n",
            "Epoch 38/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.7771\n",
            "Epoch 39/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.7641\n",
            "Epoch 40/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.7453\n",
            "Epoch 41/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.7273\n",
            "Epoch 42/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.7079\n",
            "Epoch 43/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.6882\n",
            "Epoch 44/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.6699\n",
            "Epoch 45/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.6467\n",
            "Epoch 46/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.6251\n",
            "Epoch 47/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.6001\n",
            "Epoch 48/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.5736\n",
            "Epoch 49/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.5442\n",
            "Epoch 50/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.5192\n",
            "Epoch 51/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.4895\n",
            "Epoch 52/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.4571\n",
            "Epoch 53/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.4231\n",
            "Epoch 54/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.3923\n",
            "Epoch 55/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.3643\n",
            "Epoch 56/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.3327\n",
            "Epoch 57/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.2956\n",
            "Epoch 58/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.2621\n",
            "Epoch 59/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.2342\n",
            "Epoch 60/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.1965\n",
            "Epoch 61/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.1707\n",
            "Epoch 62/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.1326\n",
            "Epoch 63/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.1023\n",
            "Epoch 64/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.0678\n",
            "Epoch 65/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.0443\n",
            "Epoch 66/200\n",
            "7/7 - 0s - 6ms/step - loss: 1.0184\n",
            "Epoch 67/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.9851\n",
            "Epoch 68/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.9609\n",
            "Epoch 69/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.9295\n",
            "Epoch 70/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.9037\n",
            "Epoch 71/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.8771\n",
            "Epoch 72/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.8522\n",
            "Epoch 73/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.8338\n",
            "Epoch 74/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.8100\n",
            "Epoch 75/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.7917\n",
            "Epoch 76/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.7669\n",
            "Epoch 77/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.7438\n",
            "Epoch 78/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.7304\n",
            "Epoch 79/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.7052\n",
            "Epoch 80/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.6906\n",
            "Epoch 81/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.6756\n",
            "Epoch 82/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.6538\n",
            "Epoch 83/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.6345\n",
            "Epoch 84/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.6261\n",
            "Epoch 85/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.6040\n",
            "Epoch 86/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.5931\n",
            "Epoch 87/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.5733\n",
            "Epoch 88/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.5651\n",
            "Epoch 89/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.5549\n",
            "Epoch 90/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.5389\n",
            "Epoch 91/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.5250\n",
            "Epoch 92/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.5142\n",
            "Epoch 93/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4999\n",
            "Epoch 94/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4914\n",
            "Epoch 95/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4727\n",
            "Epoch 96/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4630\n",
            "Epoch 97/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4517\n",
            "Epoch 98/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4433\n",
            "Epoch 99/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4313\n",
            "Epoch 100/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4264\n",
            "Epoch 101/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4113\n",
            "Epoch 102/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.4050\n",
            "Epoch 103/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3909\n",
            "Epoch 104/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3862\n",
            "Epoch 105/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.3718\n",
            "Epoch 106/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3635\n",
            "Epoch 107/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3590\n",
            "Epoch 108/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3505\n",
            "Epoch 109/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3442\n",
            "Epoch 110/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3396\n",
            "Epoch 111/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3256\n",
            "Epoch 112/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3199\n",
            "Epoch 113/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3124\n",
            "Epoch 114/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.3010\n",
            "Epoch 115/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2973\n",
            "Epoch 116/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2909\n",
            "Epoch 117/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2830\n",
            "Epoch 118/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2741\n",
            "Epoch 119/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2707\n",
            "Epoch 120/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2642\n",
            "Epoch 121/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2564\n",
            "Epoch 122/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2523\n",
            "Epoch 123/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2446\n",
            "Epoch 124/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2417\n",
            "Epoch 125/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2350\n",
            "Epoch 126/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2288\n",
            "Epoch 127/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.2225\n",
            "Epoch 128/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.2189\n",
            "Epoch 129/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.2150\n",
            "Epoch 130/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.2094\n",
            "Epoch 131/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.2029\n",
            "Epoch 132/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1999\n",
            "Epoch 133/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1948\n",
            "Epoch 134/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1908\n",
            "Epoch 135/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1862\n",
            "Epoch 136/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1804\n",
            "Epoch 137/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1763\n",
            "Epoch 138/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1721\n",
            "Epoch 139/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1684\n",
            "Epoch 140/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1643\n",
            "Epoch 141/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1604\n",
            "Epoch 142/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1582\n",
            "Epoch 143/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1541\n",
            "Epoch 144/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.1510\n",
            "Epoch 145/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1466\n",
            "Epoch 146/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1441\n",
            "Epoch 147/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1403\n",
            "Epoch 148/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1374\n",
            "Epoch 149/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1349\n",
            "Epoch 150/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1321\n",
            "Epoch 151/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1282\n",
            "Epoch 152/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.1260\n",
            "Epoch 153/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1234\n",
            "Epoch 154/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1214\n",
            "Epoch 155/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1191\n",
            "Epoch 156/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1164\n",
            "Epoch 157/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1134\n",
            "Epoch 158/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1124\n",
            "Epoch 159/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1088\n",
            "Epoch 160/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1079\n",
            "Epoch 161/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1039\n",
            "Epoch 162/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1022\n",
            "Epoch 163/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.1006\n",
            "Epoch 164/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0981\n",
            "Epoch 165/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0967\n",
            "Epoch 166/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0945\n",
            "Epoch 167/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0928\n",
            "Epoch 168/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0914\n",
            "Epoch 169/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0895\n",
            "Epoch 170/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0875\n",
            "Epoch 171/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0859\n",
            "Epoch 172/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0839\n",
            "Epoch 173/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0826\n",
            "Epoch 174/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0809\n",
            "Epoch 175/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0797\n",
            "Epoch 176/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0783\n",
            "Epoch 177/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0768\n",
            "Epoch 178/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0757\n",
            "Epoch 179/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.0739\n",
            "Epoch 180/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0730\n",
            "Epoch 181/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0716\n",
            "Epoch 182/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0703\n",
            "Epoch 183/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0692\n",
            "Epoch 184/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0678\n",
            "Epoch 185/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0671\n",
            "Epoch 186/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0657\n",
            "Epoch 187/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0641\n",
            "Epoch 188/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0634\n",
            "Epoch 189/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0620\n",
            "Epoch 190/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0613\n",
            "Epoch 191/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0601\n",
            "Epoch 192/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0592\n",
            "Epoch 193/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0581\n",
            "Epoch 194/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0575\n",
            "Epoch 195/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0564\n",
            "Epoch 196/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0556\n",
            "Epoch 197/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0549\n",
            "Epoch 198/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0537\n",
            "Epoch 199/200\n",
            "7/7 - 0s - 5ms/step - loss: 0.0529\n",
            "Epoch 200/200\n",
            "7/7 - 0s - 6ms/step - loss: 0.0522\n",
            "Model training completed.\n",
            "Random starting point for prediction: 1\n",
            "Original pattern for prediction: [[0.14285714]\n",
            " [0.28571429]\n",
            " [0.42857143]]\n",
            "Reshaped pattern for prediction: [[[0.14285714]\n",
            "  [0.28571429]\n",
            "  [0.42857143]]]\n",
            "Prediction probabilities: [[3.0981512e-06 1.1528364e-07 6.4256951e-09 3.0195404e-02 9.4391739e-01\n",
            "  2.5087669e-02 7.9627993e-04]]\n",
            "Predicted index: 4\n",
            "Predicted next note: G\n",
            "Input Sequence: ['D', 'E', 'F']\n",
            "Predicted Next Note: G\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Step 1: Define the set of notes\n",
        "# Define the musical notes that will be used in the sequence\n",
        "the_notes = ['C', 'D', 'E', 'F', 'G', 'A', 'B']\n",
        "\n",
        "# Create mappings from notes to integers and vice versa\n",
        "# This will allow conversion between notes and numerical representations\n",
        "note_to_int = dict((note, number) for number, note in enumerate(the_notes))\n",
        "int_to_note = dict((number, note) for number, note in enumerate(the_notes))\n",
        "\n",
        "# Step 2: Create a sequence of notes\n",
        "# Define a sequence of notes that will be used as input data\n",
        "sequence = ['C', 'D', 'E', 'F', 'G', 'A', 'B', 'C', 'D', 'E']\n",
        "\n",
        "# Convert the sequence of notes to integers using the mapping\n",
        "dense_sequence_int = [note_to_int[note] for note in sequence]\n",
        "print(f\"Converted sequence to integers: {dense_sequence_int}\")\n",
        "\n",
        "# Step 3: Prepare the data\n",
        "# Define the length of the input sequences (number of notes to consider in each step)\n",
        "seq_length = 3 # Number of previous notes to consider\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Create sequences for training the LSTM model\n",
        "# X will contain sequences of notes, and y will contain the next note in the sequence\n",
        "for i in range(len(dense_sequence_int) - seq_length):\n",
        "  X.append(dense_sequence_int[i:i + seq_length]) # Add the input sequence of length `seq_length`\n",
        "  y.append(dense_sequence_int[i + seq_length]) # Add the next note as the target output\n",
        "print(f\"Sequence {i}: Input: {X[-1]}, Output: {y[-1]}\")\n",
        "\n",
        "# Convert the input and output to numpy arrays for LSTM compatibility\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "# Reshape X to be [samples, time steps, features] as required by LSTM input\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "print(f\"Reshaped X: {X.shape}\")\n",
        "\n",
        "# Normalize input data by dividing by the number of notes (to have values between 0 and 1)\n",
        "X = X / float(len(the_notes))\n",
        "print(f\"Normalized X: {X}\")\n",
        "\n",
        "# Step 4: Build the model\n",
        "# Create a Sequential LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an LSTM layer with 50 units\n",
        "# The input shape is defined as (sequence length, 1 feature per time step)\n",
        "model.add(LSTM(50, input_shape=(X.shape[1], X.shape[2])))\n",
        "print(\"Added LSTM layer with 50 units.\")\n",
        "\n",
        "# Add a Dense layer with output size equal to the number of notes\n",
        "# Use 'softmax' activation to predict the probability of each note\n",
        "model.add(Dense(len(the_notes), activation='softmax'))\n",
        "print(\"Added Dense layer with softmax activation.\")\n",
        "\n",
        "# Compile the model using sparse categorical crossentropy as the loss function\n",
        "# and 'adam' as the optimizer to train efficiently\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "print(\"Compiled the model with sparse categorical crossentropy and adam optimizer.\")\n",
        "\n",
        "# Step 5: Train the model\n",
        "# Train the LSTM model on the prepared data\n",
        "# Set the number of epochs to 200, with a batch size of 1\n",
        "print(\"Starting model training...\")\n",
        "model.fit(X, y, epochs=200, batch_size=1, verbose=2)\n",
        "print(\"Model training completed.\")\n",
        "\n",
        "# Step 6: Make a prediction\n",
        "# Select a random starting point in the input data for prediction\n",
        "start = np.random.randint(0, len(X) - 1)\n",
        "print(f\"Random starting point for prediction: {start}\")\n",
        "\n",
        "# Extract the pattern to start the prediction (input sequence of length `seq_length`)\n",
        "pattern = X[start]\n",
        "pattern_original = pattern.copy() # Store a copy of the original input pattern\n",
        "print(f\"Original pattern for prediction: {pattern_original}\")\n",
        "\n",
        "# Reshape the pattern to match the LSTM input requirements (1 sample, sequence length, 1 feature)\n",
        "prediction_input = pattern.reshape(1, seq_length, 1)\n",
        "print(f\"Reshaped pattern for prediction: {prediction_input}\")\n",
        "\n",
        "# Predict the next note using the trained model\n",
        "# The prediction contains probabilities for each note\n",
        "prediction = model.predict(prediction_input, verbose=0)\n",
        "print(f\"Prediction probabilities: {prediction}\")\n",
        "\n",
        "# Extract the index of the note with the highest probability\n",
        "index = np.argmax(prediction)\n",
        "print(f\"Predicted index: {index}\")\n",
        "\n",
        "# Convert the predicted index back to the note using `int_to_note` mapping\n",
        "result = int_to_note[index]\n",
        "print(f\"Predicted next note: {result}\")\n",
        "\n",
        "# Convert the original input pattern back to note names for printing\n",
        "input_notes = [int_to_note[int(n * len(the_notes))] for n in pattern_original.flatten()]\n",
        "\n",
        "# Print the input sequence and the predicted next note\n",
        "print(f\"Input Sequence: {input_notes}\")\n",
        "print(f\"Predicted Next Note: {result}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Input Sequence Prediction Using LSTM\n",
        "\n",
        "This section of the Google Colab notebook extends the functionality of our LSTM-based music prediction model by allowing us to make predictions on a custom input sequence of notes. The idea is to feed a sequence of notes into the pre-trained model and have it predict the next note in the sequence. This is particularly useful for experimenting with different musical sequences, understanding how the model interprets them, and exploring the potential of generating new music based on user-defined inputs.\n",
        "\n",
        "### Overview of Key Steps and Ideas\n",
        "\n",
        "**1. Define the Custom Sequence of Notes**  \n",
        "- The code begins by allowing you to define a custom sequence of notes that you wish to use for prediction. For instance, you can replace the sequence `['E', 'A', 'A']` with any set of notes you are interested in. The ability to specify your own sequence offers flexibility in testing the model's ability to predict different musical contexts.\n",
        "\n",
        "**2. Data Validation and Conversion**  \n",
        "- The next step ensures that all notes in the custom sequence are valid. Specifically, the code checks if each note is part of the predefined set of notes (`the_notes`). If any note is not recognized, the code raises an error to prevent incorrect input from being processed.\n",
        "- Once validated, the custom sequence is converted to its integer representation using the mapping dictionary (`note_to_int`). This conversion is necessary because the LSTM model expects numerical input rather than text-based note labels.\n",
        "\n",
        "**3. Prepare Input Data for the Model**  \n",
        "- The custom sequence, now represented by integers, is converted into a NumPy array. To feed it into the model, the sequence is reshaped to meet the LSTM input requirements, which expect input in the shape of `[samples, time steps, features]`. Here, the input is reshaped to have one sample, with the length of the custom sequence representing the time steps, and each time step having one feature.\n",
        "- Additionally, the input data is normalized by dividing it by the number of notes (`float(len(the_notes))`). Normalization helps improve the model's learning efficiency by ensuring that all input values fall within the range [0, 1]. This step is crucial for maintaining consistency between the format of the training data and the custom input data.\n",
        "\n",
        "**4. Making Predictions with the Model**  \n",
        "- After preparing the input, the code uses the pre-trained LSTM model to predict the next note in the sequence. The model outputs a probability distribution over all possible notes, indicating the likelihood of each note being the next in the sequence.\n",
        "- The `np.argmax()` function is then used to identify the note with the highest probability, which is considered the model's prediction for the next note.\n",
        "- Finally, the predicted note index is converted back to its original note label using the `int_to_note` mapping dictionary. This allows us to display the result in a human-readable format, showing both the input sequence and the predicted next note.\n",
        "\n",
        "### How to Use This Code\n",
        "\n",
        "1. **Modify the Custom Sequence**  \n",
        "   - You can customize the sequence of notes by changing the `custom_sequence` variable. For example, you might choose `['C', 'G', 'E']` or any other combination of notes to see how the model continues the sequence.\n",
        "\n",
        "2. **Run the Code**  \n",
        "   - Ensure that the model has already been trained before running this custom prediction code. Otherwise, the model won't be able to generate meaningful predictions.\n",
        "   - Execute each step in order to convert the notes, prepare the input, and make a prediction.\n",
        "\n",
        "3. **Interpreting the Output**  \n",
        "   - The code will print the custom input sequence you provided, as well as the predicted next note. The prediction is based on the patterns learned by the LSTM during training, and it is interesting to see whether the prediction aligns with typical musical expectations.\n",
        "\n",
        "### Practical Applications and Extensions\n",
        "\n",
        "- **Music Composition:** This functionality can be used for music composition by allowing users to iteratively generate new notes, potentially creating entire pieces of music by repeatedly feeding predictions back into the model.\n",
        "- **Experimenting with Different Sequences:** You can explore how different input sequences lead to different predictions, helping you understand the types of musical patterns the model has learned.\n",
        "- **Interactive Music Generation:** By wrapping this process in a user interface, you could build an interactive music generation tool where users can input sequences and hear the model's predicted continuations in real time.\n",
        "\n",
        "This extension of the LSTM model to custom input sequences provides a powerful tool for anyone interested in understanding or creating music using deep learning. It highlights the potential of AI in generating creative outputs that can augment human creativity.\n"
      ],
      "metadata": {
        "id": "oWiOWG0Is7VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Custom Input Sequence Prediction ---\n",
        "\n",
        "# Step 1: Define your custom sequence\n",
        "# Define a custom sequence of notes to use for prediction\n",
        "custom_sequence = ['E', 'A', 'A'] # Replace with your desired notes\n",
        "print(f\"Custom input sequence: {custom_sequence}\")\n",
        "\n",
        "# Step 2: Convert notes to integers\n",
        "# Check if all notes are in the defined set of notes\n",
        "for note in custom_sequence:\n",
        "  if note not in note_to_int:\n",
        "    raise ValueError(f\"Note '{note}' is not in the defined set of notes.\")\n",
        "print(\"All custom sequence notes are valid.\")\n",
        "\n",
        "# Convert the custom sequence to integers using the mapping\n",
        "custom_sequence_int = [note_to_int[note] for note in custom_sequence]\n",
        "print(f\"Custom sequence converted to integers: {custom_sequence_int}\")\n",
        "\n",
        "# Step 3: Prepare the input data\n",
        "# Convert the custom sequence into a numpy array and reshape it\n",
        "custom_input = np.array(custom_sequence_int)\n",
        "custom_input = custom_input.reshape(1, len(custom_input), 1)\n",
        "print(f\"Reshaped custom input: {custom_input}\")\n",
        "\n",
        "# Normalize the custom input data by dividing by the number of notes (to have values between 0 and 1)\n",
        "custom_input = custom_input / float(len(the_notes))\n",
        "print(f\"Normalized custom input: {custom_input}\")\n",
        "\n",
        "# Step 4: Make the prediction\n",
        "# Predict the next note based on the custom input sequence\n",
        "prediction = model.predict(custom_input, verbose=0)\n",
        "print(f\"Custom input prediction probabilities: {prediction}\")\n",
        "\n",
        "# Extract the index of the note with the highest probability\n",
        "index = np.argmax(prediction)\n",
        "print(f\"Predicted index for custom input: {index}\")\n",
        "\n",
        "# Convert the predicted index back to the note using `int_to_note` mapping\n",
        "predicted_note = int_to_note[index]\n",
        "print(f\"Predicted next note for custom input: {predicted_note}\")\n",
        "\n",
        "# Display the result\n",
        "# Print the custom input sequence and the predicted next note\n",
        "print(f\"Input Sequence: {custom_sequence}\")\n",
        "print(f\"Predicted Next Note: {predicted_note}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyNu1Ff5sXTM",
        "outputId": "31af20f7-045f-4e80-9331-98578f21e585"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom input sequence: ['E', 'A', 'A']\n",
            "All custom sequence notes are valid.\n",
            "Custom sequence converted to integers: [2, 5, 5]\n",
            "Reshaped custom input: [[[2]\n",
            "  [5]\n",
            "  [5]]]\n",
            "Normalized custom input: [[[0.28571429]\n",
            "  [0.71428571]\n",
            "  [0.71428571]]]\n",
            "Custom input prediction probabilities: [[5.7655270e-04 5.4495154e-06 4.8819984e-08 1.6732538e-06 1.2921812e-02\n",
            "  9.0109181e-01 8.5402712e-02]]\n",
            "Predicted index for custom input: 5\n",
            "Predicted next note for custom input: A\n",
            "Input Sequence: ['E', 'A', 'A']\n",
            "Predicted Next Note: A\n"
          ]
        }
      ]
    }
  ]
}